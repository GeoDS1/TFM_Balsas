{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a48a750-06c9-4856-83c7-2764264b5530",
   "metadata": {},
   "source": [
    "# 05 Preparación del Dataset y Entrenamiento con Yolov8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ef7cd-1cfb-4458-8658-7882dd7787ec",
   "metadata": {},
   "source": [
    "Este notebook describe el proceso fundamental para preparar el dataset y entrenar el modelo de detección de balsas utilizando la arquitectura YOLOv8-obb. Se detalla la creación de la estructura de directorios necesaria para el entrenamiento, validación y prueba, así como la configuración del archivo YAML que define el dataset para YOLOv8. Finalmente, se presenta un ejemplo de código para iniciar el entrenamiento del modelo utilizando un modelo pre-entrenado y ajustarlo a nuestro conjunto de datos específico, pero el entrenamiento, devido a las limitaciones del equipo local debemos realizarlo en Google Colab utilizando el siguiente Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da3df9-07e7-4b53-ae44-ac47ee1c3c01",
   "metadata": {},
   "source": [
    "Texto breve introductorio para presentar el modelo y describir als fases\n",
    "* Creación del dataset\n",
    "* Entrenar el modelo (Google Colab)\n",
    "* Validar el modelo (Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a8c7c-6228-4390-8ee3-831076fe1d38",
   "metadata": {},
   "source": [
    "## Estructuración del Dataset para Entrenamiento de YOLOv8\n",
    "\n",
    "Para entrenar un modelo de detección de objetos con YOLOv8, es fundamental estructurar el dataset de manera adecuada. Esto incluye organizar las imágenes y sus correspondientes etiquetas en carpetas específicas para los conjuntos de entrenamiento (`train`), validación (`val`) y prueba (`test`). Además, se deben seguir proporciones estándar para garantizar que el modelo se entrene correctamente y pueda generalizar bien a datos no vistos.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Dataset\n",
    "El dataset debe estar organizado en una estructura jerárquica como la siguiente:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── images/\n",
    "│   ├── train/       # Imágenes para entrenamiento\n",
    "│   ├── val/         # Imágenes para validación\n",
    "│   └── test/        # Imágenes para prueba\n",
    "└── labels/\n",
    "    ├── train/       # Etiquetas para entrenamiento\n",
    "    ├── val/         # Etiquetas para validación\n",
    "    └── test/        # Etiquetas para prueba\n",
    "```\n",
    "\n",
    "Cada imagen en las carpetas `images` debe tener un archivo de texto correspondiente en las carpetas `labels`, con el mismo nombre pero extensión `.txt`. Estos archivos contienen las anotaciones (etiquetas) en formato YOLO-obb, que describen las posiciones y clases de los objetos presentes en la imagen.\n",
    "\n",
    "---\n",
    "\n",
    "### Proporciones de Datos\n",
    "Es común dividir el dataset en las siguientes proporciones:\n",
    "- **70%** para entrenamiento (`train`): El conjunto de datos utilizado para que el modelo aprenda los patrones característicos de las balsas.\n",
    "- **20%** para validación (`val`): Un conjunto de datos separado que se utiliza para monitorear el rendimiento del modelo durante el entrenamiento y ajustar hiperparámetros\n",
    "- **10%** para prueba (`test`): Un conjunto de datos final e independiente que se utiliza para evaluar el rendimiento del modelo entrenado en datos completamente nuevos, proporcionando una estimación de su capacidad de generalización.\n",
    "\n",
    "Esto asegura que haya suficientes datos para entrenar el modelo, mientras se reserva una parte para validar su rendimiento durante el entrenamiento y otra para evaluarlo al final.\n",
    "\n",
    "---\n",
    "\n",
    "El siguiente código implementa un flujo de trabajo eficiente para preparar un dataset compatible con YOLOv8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce35bbb2-35c0-4f26-a1e0-f5908dd78316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias necesarias\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f567b391-556a-489c-94ea-2344c35037a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos válidos con imagen y etiqueta: 593\n",
      "Distribución de datos:\n",
      "  - Train: 415 archivos (70.0%)\n",
      "  - Validación: 118 archivos (19.9%)\n",
      "  - Test: 60 archivos (10.1%)\n",
      "Copiando archivos para train...\n",
      "Se copiaron 415 archivos al conjunto train\n",
      "Copiando archivos para val...\n",
      "Se copiaron 118 archivos al conjunto val\n",
      "Copiando archivos para test...\n",
      "Se copiaron 60 archivos al conjunto test\n",
      "\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Definición de rutas\n",
    "input_images_dir = Path(\"../data/interim/dataset/images\")\n",
    "input_labels_dir = Path(\"../data/interim/dataset/labels_obb\")\n",
    "\n",
    "output_base_dir = Path(\"../data/processed/dataset\")\n",
    "output_dirs = {\n",
    "    \"train\": {\n",
    "        \"images\": output_base_dir / \"images\" / \"train\",\n",
    "        \"labels\": output_base_dir / \"labels\" / \"train\"\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"images\": output_base_dir / \"images\" / \"val\",\n",
    "        \"labels\": output_base_dir / \"labels\" / \"val\"\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"images\": output_base_dir / \"images\" / \"test\",\n",
    "        \"labels\": output_base_dir / \"labels\" / \"test\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear directorios de salida si no existen\n",
    "for split in output_dirs.values():\n",
    "    for dir_path in split.values():\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Obtener nombres de archivos de imágenes (sin extensión)\n",
    "image_files = []\n",
    "for file_path in input_images_dir.glob(\"*\"):\n",
    "    if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:\n",
    "        image_files.append(file_path.stem)\n",
    "\n",
    "# Obtener nombres de archivos de etiquetas (sin extensión)\n",
    "label_files = []\n",
    "for file_path in input_labels_dir.glob(\"*.txt\"):\n",
    "    if file_path.is_file():\n",
    "        label_files.append(file_path.stem)\n",
    "\n",
    "# Verificar coincidencia de archivos\n",
    "image_set = set(image_files)\n",
    "label_set = set(label_files)\n",
    "\n",
    "# Archivos en imágenes pero no en etiquetas\n",
    "only_in_images = image_set - label_set\n",
    "if only_in_images:\n",
    "    print(f\"ADVERTENCIA: {len(only_in_images)} archivos de imagen no tienen etiquetas correspondientes:\")\n",
    "    for file in list(only_in_images)[:5]:  # Mostrar solo los primeros 5 para no saturar la salida\n",
    "        print(f\"  - {file}\")\n",
    "    if len(only_in_images) > 5:\n",
    "        print(f\"  ... y {len(only_in_images) - 5} más\")\n",
    "\n",
    "# Archivos en etiquetas pero no en imágenes\n",
    "only_in_labels = label_set - image_set\n",
    "if only_in_labels:\n",
    "    print(f\"ADVERTENCIA: {len(only_in_labels)} archivos de etiquetas no tienen imágenes correspondientes:\")\n",
    "    for file in list(only_in_labels)[:5]:\n",
    "        print(f\"  - {file}\")\n",
    "    if len(only_in_labels) > 5:\n",
    "        print(f\"  ... y {len(only_in_labels) - 5} más\")\n",
    "\n",
    "# Usar solo archivos que tengan tanto imagen como etiqueta\n",
    "valid_files = list(image_set.intersection(label_set))\n",
    "print(f\"Archivos válidos con imagen y etiqueta: {len(valid_files)}\")\n",
    "\n",
    "if not valid_files:\n",
    "    print(\"ERROR: No hay archivos válidos para procesar.\")\n",
    "    exit(1)\n",
    "\n",
    "# Mezclar aleatoriamente los archivos\n",
    "random.seed(42) \n",
    "random.shuffle(valid_files)\n",
    "\n",
    "# Calcular los tamaños de cada conjunto\n",
    "total = len(valid_files)\n",
    "train_size = int(total * 0.7)\n",
    "val_size = int(total * 0.2)\n",
    "# El resto va a test\n",
    "\n",
    "# Dividir los archivos\n",
    "train_files = valid_files[:train_size]\n",
    "val_files = valid_files[train_size:train_size + val_size]\n",
    "test_files = valid_files[train_size + val_size:]\n",
    "\n",
    "print(f\"Distribución de datos:\")\n",
    "print(f\"  - Train: {len(train_files)} archivos ({len(train_files)/total:.1%})\")\n",
    "print(f\"  - Validación: {len(val_files)} archivos ({len(val_files)/total:.1%})\")\n",
    "print(f\"  - Test: {len(test_files)} archivos ({len(test_files)/total:.1%})\")\n",
    "\n",
    "# Función para encontrar la extensión correcta de un archivo de imagen\n",
    "def find_image_extension(filename, directory):\n",
    "    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:\n",
    "        full_path = directory / f\"{filename}{ext}\"\n",
    "        if full_path.exists():\n",
    "            return ext\n",
    "    return None\n",
    "\n",
    "# Copiar los archivos a sus respectivos directorios\n",
    "def copy_files(file_list, split_name):\n",
    "    print(f\"Copiando archivos para {split_name}...\")\n",
    "    count = 0\n",
    "    for filename in file_list:\n",
    "        # Buscar la extensión de la imagen\n",
    "        img_ext = find_image_extension(filename, input_images_dir)\n",
    "        if not img_ext:\n",
    "            print(f\"ADVERTENCIA: No se encontró la imagen para {filename}\")\n",
    "            continue\n",
    "            \n",
    "        # Ruta de origen y destino para imágenes\n",
    "        src_img = input_images_dir / f\"{filename}{img_ext}\"\n",
    "        dst_img = output_dirs[split_name][\"images\"] / f\"{filename}{img_ext}\"\n",
    "        \n",
    "        # Ruta de origen y destino para etiquetas\n",
    "        src_lbl = input_labels_dir / f\"{filename}.txt\"\n",
    "        dst_lbl = output_dirs[split_name][\"labels\"] / f\"{filename}.txt\"\n",
    "        \n",
    "        # Copiar archivos\n",
    "        try:\n",
    "            shutil.copy2(src_img, dst_img)\n",
    "            shutil.copy2(src_lbl, dst_lbl)\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error al copiar {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Se copiaron {count} archivos al conjunto {split_name}\")\n",
    "\n",
    "# Copiar todos los conjuntos\n",
    "copy_files(train_files, \"train\")\n",
    "copy_files(val_files, \"val\")\n",
    "copy_files(test_files, \"test\")\n",
    "\n",
    "print(\"\\nProceso completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b9fc20-22f2-471b-9246-d14ba3e9d70a",
   "metadata": {},
   "source": [
    "## Entrenar el modelo YOLOv8-obb \n",
    "\n",
    "Notebook: `06 Entrenamiento y Validación del Modelo (Google Colab).ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13802d2e-6e24-4eb3-939a-cbba12b440c5",
   "metadata": {},
   "source": [
    "### Google Colab\n",
    "\n",
    "Debido a la limitación de recursos de hardware disponibles localmente, específicamente la falta de una GPU con la capacidad de procesamiento necesaria, se ha recurrido al uso de las GPUs proporcionadas por Google Colab para el entrenamiento del modelo de detección de imágenes Yolov8n-obb. Esta plataforma en la nube ofrece la infraestructura computacional requerida para llevar a cabo el entrenamiento de manera eficiente, superando las limitaciones del equipo local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d152c02-2caf-468c-abf4-439cfd52575b",
   "metadata": {},
   "source": [
    "### Yolov8n-obb\n",
    "La elección del modelo Yolov8n (nano) para la detección de balsas en imágenes aéreas se fundamenta en su arquitectura ligera, diseñada para minimizar las necesidades de cómputo y acelerar significativamente los tiempos de entrenamiento. Esta optimización es crucial en el contexto de recursos limitados y la necesidad de obtener resultados en plazos razonables.\n",
    "\n",
    "Adicionalmente, se ha optado por la variante OBB (Oriented Bounding Boxes) de Yolov8 debido a su capacidad superior para la detección precisa de objetos con orientaciones arbitrarias, característica inherente a las balsas visualizadas en las imágenes aéreas. Los modelos OBB son especialmente recomendados en este tipo de aplicaciones, ya que capturan la orientación de los objetos, evitando los recortes e imprecisiones que pueden surgir con los bounding boxes axis-aligned tradicionales.\n",
    "\n",
    "Finalmente, para optimizar aún más el proceso de entrenamiento y reducir los tiempos requeridos, se empleará un modelo Yolov8 preentrenado. Este enfoque, conocido como transfer learning o fine-tuning, permite aprovechar el conocimiento previamente adquirido por el modelo en un conjunto de datos masivo. Al adaptar este modelo preentrenado utilizando nuestro conjunto de datos específico de imágenes de balsas aéreas, se logra una convergencia más rápida y se requiere una menor cantidad de datos y tiempo de entrenamiento en comparación con un entrenamiento desde cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d667d-d6db-4412-8dec-92fc6201e7f4",
   "metadata": {},
   "source": [
    "### Fichero YALM\n",
    "\n",
    "Los modelos de YOLOv8 (y en general muchos modelos de detección de **Ultralytics**) usan un **archivo `.yaml`** para **definir el conjunto de datos** que se va a utilizar para entrenamiento o inferencia.\n",
    "\n",
    "Esto incluye:\n",
    "- Las **rutas** a los datos de entrenamiento y validación\n",
    "- La **lista de clases** (etiquetas) del conjunto de datos\n",
    "- (Opcional) Formato de anotaciones, número de canales, entre otros\n",
    "\n",
    "Esto permite que el mismo modelo se entrene con distintos datasets **sin tener que modificar el código**, simplemente cambiando la ruta del archivo `.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2b503-d65a-4d6e-b3d6-ddc9ad6e1c55",
   "metadata": {},
   "source": [
    "### Ejemplo de archivo `data.yaml` para YOLOv8-obb:\n",
    "\n",
    "```yaml\n",
    "# Archivo: data.yaml\n",
    "\n",
    "# Rutas de entrenamiento/validación/prueba (ajusta según tu estructura de directorios)\n",
    "path: ../data/processed/dataset  # ruta base del dataset\n",
    "train: images/train  # ruta relativa a las imágenes de entrenamiento\n",
    "val: images/val  # ruta relativa a las imágenes de validación\n",
    "test: images/test  # ruta relativa a las imágenes de prueba (opcional)\n",
    "\n",
    "# Nombres de las clases\n",
    "names:\n",
    "  0: balsa\n",
    "\n",
    "# Información adicional\n",
    "nc: 1  # número de clases\n",
    "task: detect  # tipo de tarea: detect, segment, classify, etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8940febd-cdbb-45f9-9695-a3776b23a3a4",
   "metadata": {},
   "source": [
    "### Ejemplo básico de parámetros de entrenamiento para Yolov8n-obb\n",
    "Un ejemplo de código para entrenar Yolov8n.obb sería el siguiente.\n",
    "\n",
    "\n",
    "```python\n",
    "# Importar librería y cargar el modelo pre-entrenado\n",
    "from ultralytics import YOLO # Load a model \n",
    "model = YOLO(\"../models/yolov8n-obb.pt\")\n",
    "\n",
    "\n",
    "#Entrenar el modelo \n",
    "results = model.train( data=\"../models/data.yaml\", epochs=100, patience=15, batch=2, imgsz=640, optimizer=\"AdamW\", plots=True, save=True, project=\"deteccion_balsas\", name=\"yolov8n_obb_run1\", exist_ok=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda944cc-f175-450a-b4d3-b909c6fccd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d32648-940e-4dea-b8ce-670363a97bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
